# -*- coding: utf-8 -*-
"""資料科學從業人員薪情平台v2_區間.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lv6X71R4TL7iuNP5Ao3VT1gQ5VRi0vaD
"""


"""# 區間預測"""

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from feature_engine.encoding import RareLabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
import joblib
#%%
# ===== 讀取資料並前處理 =====
df = pd.read_csv('/Users/chencongen/Desktop/MDS培訓/sidecode/py檔案/salaries.csv')
df = df[df['employment_type'] == 'FT'].copy()
df['job_title'].replace('System Engineer', 'Systems Engineer', inplace=True)
df['job_title'].replace('Solution Engineer', 'Solutions Engineer', inplace=True)

label = 'salary_in_usd'
df[label] = df[label] * 1e-3
#%%
df = df[df[label] >= 1.0]
P = np.percentile(df[label], [0, 98])
df = df[(df[label] > P[0]) & (df[label] < P[1])]
#%%
df[label] = np.log1p(df[label])  # log轉換
#%%測試偏態
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))  # 設定圖的大小
plt.hist(df[label], bins=30, edgecolor='black')  # bins控制切幾個區間
plt.xlabel('Salary (in $1,000 USD)')
plt.ylabel('Count')
plt.title('Distribution of Modified Salaries')
plt.grid(True)
plt.show()

from scipy.stats import skew, kurtosis

print('Skewness:', skew(df[label]))
print('Kurtosis:', kurtosis(df[label]))

#%%
# ===================== 特徵工程：remote_ratio 分類轉換 =====================
conditions = [
    df['remote_ratio'] == 0,
    df['remote_ratio'] == 50,
    df['remote_ratio'] == 100
]
choices = ['Onsite', 'Hybrid', 'Remote']
df['remote_ratio'] = np.select(conditions, choices, default='Unknown')

df['residence_location'] = df['employee_residence'] + '/' + df['company_location']
df['work_year'] = df['work_year'].astype(str)
job_titles_raw = df['job_title'].copy()

cols2drop = ['salary', 'employee_residence', 'company_location', 'salary_currency', 'employment_type']
df.drop(cols2drop, axis=1, inplace=True)

cat_cols = [col for col in df.columns if col != label and col != 'job_title']
for col in cat_cols:
    df[col] = df[col].fillna('None').astype(str)
    encoder = RareLabelEncoder(n_categories=1, max_n_categories=100, replace_with='Other', tol=30/df.shape[0])
    df[col] = encoder.fit_transform(df[[col]])

y = df[label].values.reshape(-1,)
X = df.drop(columns=[label])
X['job_title_raw'] = job_titles_raw

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=X[['residence_location']])
#%%
# ===== TF-IDF + SVD 處理 job_title =====
tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=100)
X_train_job_tfidf = tfidf.fit_transform(X_train['job_title_raw'])
X_test_job_tfidf = tfidf.transform(X_test['job_title_raw'])

svd = TruncatedSVD(n_components=20, random_state=42)
X_train_tfidf_svd = svd.fit_transform(X_train_job_tfidf)
X_test_tfidf_svd = svd.transform(X_test_job_tfidf)

X_train_tfidf_df = pd.DataFrame(X_train_tfidf_svd, columns=[f'tfidf_svd_{i}' for i in range(20)], index=X_train.index)
X_test_tfidf_df = pd.DataFrame(X_test_tfidf_svd, columns=[f'tfidf_svd_{i}' for i in range(20)], index=X_test.index)

X_train = pd.concat([X_train.drop(columns=['job_title', 'job_title_raw']), X_train_tfidf_df], axis=1)
X_test = pd.concat([X_test.drop(columns=['job_title', 'job_title_raw']), X_test_tfidf_df], axis=1)

cat_features = [col for col in X_train.columns if not col.startswith('tfidf_svd_')]
for col in cat_features:
    X_train[col] = X_train[col].astype('category')
    X_test[col] = X_test[col].astype('category')
#%%
# ===== LightGBM Dataset（保留原始資料） =====
train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features, free_raw_data=False)
valid_data = lgb.Dataset(X_test, label=y_test, categorical_feature=cat_features, free_raw_data=False)
#%%
# ===== Quantile Regression 模型參數 =====
base_params = {
    'metric': 'quantile',
    'learning_rate': 0.011167530436266263,
    'num_leaves': 39,
    'max_depth': 6,
    'min_data_in_leaf': 16,
    'feature_fraction': 0.91521788003488,
    'bagging_fraction': 0.9349006039224463,
    'bagging_freq': 2,
    'lambda_l1': 0.8081898917059471,
    'lambda_l2': 0.45680204294902715,
    'verbose': -1,
    'force_col_wise': True
}

params_lower = base_params.copy()
params_lower['objective'] = 'quantile'
params_lower['alpha'] = 0.05

params_upper = base_params.copy()
params_upper['objective'] = 'quantile'
params_upper['alpha'] = 0.95

# ===== 訓練上下限模型 =====
model_lower = lgb.train(
    params_lower,
    train_data,
    valid_sets=[valid_data],
    valid_names=['valid'],
    num_boost_round=10000,
    callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(period=100)]
)

model_upper = lgb.train(
    params_upper,
    train_data,
    valid_sets=[valid_data],
    valid_names=['valid'],
    num_boost_round=10000,
    callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(period=100)]
)
#%%
# ===== 區間預測結果（log還原） =====
pred_lower = np.expm1(model_lower.predict(X_test)) * 1000
pred_upper = np.expm1(model_upper.predict(X_test)) * 1000
#%%
# ===== 區間預測結果（log還原） =====
pred_lower = (model_lower.predict(X_test)) * 1000
pred_upper = (model_upper.predict(X_test)) * 1000
#%%
print(y_pred_lower,y_pred_upper)

#%%
y_test = (y_test)*1000
y_true = y_test
import numpy as np

# 計算 PICP
picp = np.mean((y_true >= pred_lower) & (y_true <= pred_upper))

# 計算 MPIW
mpiw = np.mean(pred_upper - pred_lower)

# 計算 PINAW
pinaw = mpiw / (np.max(y_true) - np.min(y_true))

print(f'PICP: {picp:.4f}')
print(f'MPIW: {mpiw:.4f}')
print(f'PINAW: {pinaw:.4f}')

#%%
# ===== Pipeline 封裝與儲存 =====
encoders = {}
for col in cat_cols:
    encoder = RareLabelEncoder(n_categories=1, max_n_categories=100, replace_with='Other', tol=30/df.shape[0])
    encoder.fit(df[[col]])
    encoders[col] = encoder

pipeline = {
    'model_lower': model_lower,
    'model_upper': model_upper,
    'tfidf': tfidf,
    'svd': svd,
    'encoders': encoders,
    'cat_features': cat_features,
    'tfidf_cols': [f'tfidf_svd_{i}' for i in range(20)]
}

joblib.dump(pipeline, 'salary_interval_pred_lgb.pkl')

y_true = np.expm1(y_test) * 1000
coverage = np.mean((y_true >= y_pred_lower) & (y_true <= y_pred_upper))
print(f'Coverage rate: {coverage:.2%}')

import numpy as np
import pandas as pd
import joblib

# 載入儲存的 pipeline
pipeline = joblib.load('salary_interval_pred_lgb.pkl')

model_lower = pipeline['model_lower']
model_upper = pipeline['model_upper']
tfidf = pipeline['tfidf']
svd = pipeline['svd']
encoders = pipeline['encoders']
cat_features = pipeline['cat_features']
tfidf_cols = pipeline['tfidf_cols']
#%%
def predict_salary_interval(input_data: pd.DataFrame) -> pd.DataFrame:
    """
    預測薪資區間（下限與上限）

    Args:
        input_data (pd.DataFrame): 欲預測資料（包含與訓練時相同的欄位）

    Returns:
        pd.DataFrame: 包含預測下限與上限的結果
    """

    # 特徵前處理
    input_data = input_data.copy()
    input_data['residence_location'] = input_data['employee_residence'] + '/' + input_data['company_location']
    input_data['work_year'] = input_data['work_year'].astype(str)
    input_data['job_title'].replace('System Engineer', 'Systems Engineer', inplace=True)
    input_data['job_title'].replace('Solution Engineer', 'Solutions Engineer', inplace=True)
    input_data['job_title_raw'] = input_data['job_title']

    # 處理分類欄位
    for col in cat_features:
        input_data[col] = input_data[col].fillna('None').astype(str)
        input_data[col] = encoders[col].transform(input_data[[col]])

    # 處理 TF-IDF + SVD 特徵
    job_title_tfidf = tfidf.transform(input_data['job_title_raw'])
    job_title_svd = svd.transform(job_title_tfidf)
    tfidf_df = pd.DataFrame(job_title_svd, columns=tfidf_cols, index=input_data.index)

    input_data = pd.concat([input_data.drop(columns=['job_title', 'job_title_raw']), tfidf_df], axis=1)

    # 移除未在訓練資料中使用的欄位
    cols2drop = ['employment_type', 'salary_currency', 'employee_residence', 'company_location']
    input_data.drop(columns=cols2drop, inplace=True, errors='ignore')

    # 類別特徵轉型
    for col in cat_features:
        input_data[col] = input_data[col].astype('category')

    # 預測上下限（log 還原 + 乘以 1000）
    y_lower = np.expm1(model_lower.predict(input_data)) * 1000
    y_upper = np.expm1(model_upper.predict(input_data)) * 1000

    result = pd.DataFrame({
        'predicted_salary_lower': y_lower,
        'predicted_salary_upper': y_upper
    }, index=input_data.index)

    return result
#%%
# 範例輸入資料（需符合訓練格式）
new_data = pd.DataFrame([{
    'work_year': '2024',
    'experience_level': 'SE',
    'employment_type': 'FT',
    'job_title': 'Data Scientist',
    'salary_currency': 'USD',
    'employee_residence': 'US',
    'remote_ratio': 0,
    'company_location': 'US',
    'company_size': 'L'
}])
#%%
# 執行預測
predicted_interval = predict_salary_interval(new_data)
print(predicted_interval)